\chapter{Inferenz und Resolution}
\label{chap:inferenz_resolution}

\section{Inferenz}
\label{sec:inferenz}
Grundsätzlich geht es bei Inferenz um den Prozess von Schlussfolgerungen mithilfe von Resolution (siehe~\ref{sec:resolution}). Die logische Inferenz ist ein Prozess der Inferenz und Resolution, welcher die Folgebeziehungen zwischen Sätzen zum Ausdruck bringt.~\cite[S. 163]{russel}.

\subsection{Inferenz in Computern}
\label{subsec:inferenz-in-computer}

Das grundsätzliche Problem bei Computern im Bezug auf Inferenz ist, dass ein Computer keine Interpretation vornehmen kann und nichts über die (Um-) Welt weiss, bzw.\ nur, was in seiner Wissensdatenbank gespeichert ist (vgl.~\citet[S. 164]{russel}).


Angenommen, man möchte einen Computer fragen

\lstset{caption={Beispielanfrage an eine Wissensdatenbank eines Computers},captionpos=b}
\begin{lstlisting}
    ``Ist eine Abenteuerreise eine Reise?''
\end{lstlisting}

so weiss der Computer weder was ein Abenteuerreise ist, noch kennt er das Konzept des Reisens an sich. Das Einzige, was er tun kann, ist, in der Wissensdatenbank nach 

\lstset{caption={Aussage in einer Wissensdatenbank eines Computers},captionpos=b}
\begin{lstlisting}
    ``Eine Abenteuerreise ist eine Reise.''
\end{lstlisting}

zu suchen. Findet der Computer diese Aussage in der Wissensdatenbank, so spielt es keine Rolle, dass er das Konzept der Abenteuerreise oder des Reisens nicht kennt. Die Schlussfolgerung, dass eine Abenteuerreise eine Reise ist, trifft unter allen Gegebenheiten und Interpretationen zu, welche für die Wissensdatenbank zutreffen (vgl.~\cite[S.164]{russel}).

Zusammengefasst kann gesagt werden, dass die formale Inferenz in der Lage ist, gültige Schlussfolgerungen zu ziehen, auch wenn der Computer die Interpretationen des Anwenders nicht kennt. Der Computer zieht immer logisch gültige Schlüsse, unabhängig von der (menschlichen) Interpretation. Da der Mensch in der Regel die Interpretation kennt, erscheinen die Schlüsse dem Menschen logisch (vgl.~\cite[S. 165]{russel}).

\section{Resolution}
\label{sec:resolution}

Resolution, aus dem Lateinischen ``resolutio'', zu Deutsch ``Auflösung'', ist eine Verallgemeinerung des Modus Ponens~\cite[S. 279]{russel}. Die Methode der Resolution wurde 1965 von J. A. Robinson entwickelt, dabei handelt es sich um einen vollständigen Algorithmus der Theorembeweisung für Prädikatenlogik erster Stufe.~\cite[S. 18]{russel} In der einfachsten Form handelt es sich bei der Resolution um eine Inferenz-Regel der Aussagenlogik.~\cite[S. 277]{russel}

Eine Verallgemeinerung der einfachen Form der Inferenz-Regel zur Resolution kann als Regel zur kompletten Inferenz der Prädikatenlogik erster Stufe genutzt werden.~\cite[S. 278]{russel}

\section{Inferenz und Resolution zum Ziehen von Schlüssen}
\label{sec:inferenz_praktisch}
Inferenz in der Semantik kann grundsätzlich als das Entdecken von neuen Beziehungen zwischen Entitäten beschrieben werden. Dies heisst, dass automatische Prozeduren, in Form von so genannten \textit{Reasonern}, neue Beziehungen ableiten. Wie die neuen Beziehungen generiert werden ist eine Frage der Implementation, so z.B. durch Hinzufügen zu den Daten oder durch eine einfache Rückgabe dieser (vgl.~\cite[Abschnitt 1]{w3inference}).

Reasoner sind Komponenten, welche eine Folgerung von implizitem Wissen zulassen bzw.\ bieten. Es handelt sich um eine Art ``Verstehen'' durch Maschinen. Ziel ist es implizites Wissens aus explizitem Wissen, in Form einer Ontologie, zu erschliessen.

Eine detaillierte Beschreibung solch einer praktischen Umsetzung, in Form des \textit{Pellet}-Reasoners der Firma Clark \& Parsia, findet sich im~\autoref{sec:inferenz_pellet}. Dieser basiert auf Beschreibungslogik.  Eine Einführung der Grundlagen der Beschreibungslogik folgt im nächsten Abschnitt.

\subsection{Beschreibungslogik}
\label{subsubsection:beschreibungslogik}
Beschreibungslogiken sind Formalismen um Wissen darzustellen, dabei sind sie eine Teilmenge der Prädikatenlogik. Sie stellen den Kern von Wissensrepräsentationssystemen dar, in dem sie eine Struktur für eine Wissensbasis und den damit verbundenen Methoden zur Folgerung bieten (vgl.~\cite{dl:baader2003}).

Die Struktur, welche Beschreibungslogiken als Wissensbasis bereitstellen, besteht aus einem Schema (Tbox, Regeln), sowie aus den Daten (Abox, Fakten).

Details zu Beschreibungslogiken finden sich unter~\cite{dl:baader2003}.

\subsubsection{Interpretation}
\label{subsubsection:beschreibungslogik_Interpretation}
``Man bezeichnet die Zuordnung von Ereignissen aus einer realen Welt zu aussagenlogischen Variablen als Interpretation.''~\cite[S. 36]{laemmel}

\begin{lstlisting}[caption={Definition einer Interpretation \protect\footnotemark}]
    Sei M die Menge aller aussagenlogischen Formeln. Eine Funktion
        $I : M \rightarrow \{ W , F \}$
    heisst Interpretation.
\end{lstlisting}
\footnotetext{\cite[S. 36]{laemmel}}

\subsubsection{Modell}
\label{subsubsection:beschreibungslogik_modell}
\begin{lstlisting}[caption={Definition Modell \protect\footnotemark}]
    Sei $I$ eine Interpretation und $X$ eine aussagenlogische Formel.
    Ist $X$ unter $I$ wahr, so bezeichnet man $I$ als Modell von $X$.
\end{lstlisting}
\footnotetext{\cite[S. 37]{laemmel}}

\subsubsection{Semantische Folgerung}
\label{subsubsection:beschreibungslogik_semfol}
``Der Zusammenhang von Formeln kann durch den Begriff der semantischen Folgerung dargestellt werden.''~\cite[S. 39]{laemmel}

\begin{lstlisting}[caption={Definition semantische Folgerung\protect\footnotemark}]
    Sei $X$ eine Menge von aussagenlogischen Formeln, $Y$ eine aussagenlogische Formel.
        $Y$ ist eine semantische Folgerung von $X$
    falls jedes Modell von $X$ auch Modell von $Y$ ist.
    Man schreibt dafür $X \models Y$ und sagt auch $Y$ folgt aus $X$.
\end{lstlisting}
\footnotetext{\cite[S. 39]{laemmel}}

\subsubsection{Ableitbarkeit}
\label{subsubsection:beschreibungslogik_ableitbarkeit}
Es ist erforderlich, ``\dots dass das Folgern von Formeln auf der Ebene der Gültigkeit von der Berechnung von Formeln auf der Inferenzebene unterschieden wird. Dies wird mit dem Begriff des Ableitens getan.''~\cite[S. 42]{laemmel}

\begin{lstlisting}[caption={Definition Ableitbarkeit\protect\footnotemark}]
    $Y$ ist aus $X$ ableitbar,
        $X \vdash Y$
    wenn eine endliche Folge von Inferenzschritten existiert,
    so dass man von $X$ zu $Y$ gelangt.
\end{lstlisting}
\footnotetext{\cite[S. 42]{laemmel}}

\subsubsection{Korrektheit und Vollständigkeit}
\label{subsubsection:beschreibungslogik_vollstanendigkeit}
``Der Bezug zwischen beiden Begriffen (semantische Folgerung und Ableitbarkeit, Anm.\ der Autoren) wird durch die Begriffe der Korrektheit und der Vollständigkeit hergestellt.''~\cite[S. 43]{laemmel}

\begin{lstlisting}[caption={Definition Korrektheit und Vollständigkeit\protect\footnotemark}]
    Ein Beweis-Verfahren heisst korrekt, wenn für beliebige Formeln $X, Y$ gilt:
        Falls $X \vdash Y$ gilt, dann gilt auch $X \models Y$.
    Ein Beweis-Verfahren heißt vollständig, wenn für beliebige Formeln $X, Y$ gilt:
        Falls $X \models Y$ gilt, dann gilt auch $X \vdash Y$.
\end{lstlisting}
\footnotetext{\cite[S. 43]{laemmel}}

\section{Pellet}
\label{sec:inferenz_pellet}
Sofern im Text nicht anders vermerkt, basiert das nachfolgende Kapitel auf~\cite{sirin:pellet05}.

Bei Pellet handelt es sich um einen Reasoner auf Basis von Beschreibungslogik. Eine syntaktische Variante von Beschreibungslogik ist OWL.\@ Pellet wurde von Grund auf für die OWL-DL~\footnote{\url{http://www.w3.org/TR/owl-ref/\#OWLDL}} Sprache entwickelt. Diese ist wiederum eine Teilsprache von OWL-full, siehe~\autoref{chap:owl}.

Eine komplette Unterstützung des OWL-full Profils ist so nicht möglich, da dieses nicht entscheidbar ist, daher beschränkt sich Pellet auf die Verwendung von OWL-DL\@.~\cite[Seite 13]{sirin:pellet05}

\begin{figure}[htbp]
\centering \rotatebox{0}{\scalebox{0.5}[0.5]{\includegraphics{bilder/pellet_komponenten.png}}}
\caption{Hauptkomponenten des Pellet-Reasoners.\label{fig:pellet_komponenten}\protect\footnotemark}
\end{figure}
\footnotetext{\cite[S. 6]{sirin:pellet05}}

Die obenstehende Abbildung zeigt die Hauptkomponenten von Pellet. Dabei ist der Tableaux-Reasoner die Kernkomponente des Systems, welche die Wissensbasis auf deren Konsistenz prüft. Der Designentscheid, dass Pellet von Anfang an für OWL entwickelt wurde, führte zu einer modularen Struktur. Module sind z.B.\ ein Reasoner zur Datentypenprüfung eines XML-Schemas oder eine ``Query-Engine''. Genaueres dazu wird in den nachfolgenden Abschnitten beschrieben.

Hier eine Übersicht der wichtigsten Komponenten von Pellet:
\begin{table}[H]
\centering
\fbox{\begin{minipage}[t]{0.48\linewidth}%
    \begin{tabbing}
        Abkürzung \= Bezeichnung ******** \= Beschreibung \kill \\
        ---           \> Tableaux-Reasoner  \> Komponente, zum Ziehen von Schlüssen durch Konsistenzprüfung \\
                      \>                    \> einer Ontolgie.  \\
        \textbf{Abox} \> Assertional Box    \> Komponente, welche Aussagen zu Individuen enthält, \\
                      \>                    \> also OWL-Fakten wie Typen, Eigenschaftswerte und logische Äquivalenz. \\
        \textbf{Tbox} \> Terminological Box \> Komponente, welche Klassenaxiome enthält, also OWL-Axiome \\
                      \>                    \> wie z.B. Unterklassen, Gleichheit von Klassen und Klasseneinschränkungen. \\
        \textbf{KB}   \> Knowledge Base     \> Eine Kombination einer Abox und Tbox, daher eine komplette OWL-Ontologie.
    \end{tabbing}
\end{minipage}}\hfill
\captionof{table}{Beschreibung der wichtigsten Komponenten von Pellet\protect\footnotemark}
\footnotetext{\cite[S. 4]{sirin:pellet04}}
\end{table}


\subsection{Vorgehen des Pellet-Reasoners}
\label{subsection:inferenz_pellet_vorgehen}
Wird eine Ontologie mittels Parser geladen, wird diese auf deren Gültigkeit bezüglich OWL-DL geprüft. Während des Ladens werden Klassenaxiome in der Tbox, Aussagen über Individuen in der Abox abgelegt. Die Axiome der Tbox werden durch das Standardverfahren von OWL-DL-Reasonern vorverarbeitet. Sie werden normalisiert, absorbiert und internationalisiert und anschliessend in den Tableaux-Reasoner eingespiesen.

\subsubsection{Laden und Parsen der Daten}
\label{ssubsection:inferenz_pellet_parsing}
Pellet bietet diverse Schnittstellen um Ontologien zu laden. Pellet selbst implementiert keinen RDF/OWL-Parser, ist aber in verschiedenen RDF/OWL-Werkzeugen, welche solch einen Parser anbieten, integriert. Dabei unterstützt Pellet die unterschiedlichen Datenstrukturen der Werkzeuge. Weiter stellt der Reasoner Schnittstellen um Anfragen der Werkzeuge zu beantworten zur Verfügung.

\subsubsection{Tableaux-Reasoner}
\label{ssubsection:inferenz_pellet_tableaux}
Der Tableaux-Reasoner hat nur eine Funktion: Eine Ontologie auf ihre Konsistenz zu prüfen. Eine Ontologie ist genau dann konsistent, wenn eine Interpretation der Ontologie existiert, welche alle Fakten und Axiome dieser erfüllt.~\cite{w3owlsemantics} Solch eine Interpretation wird als Modell der Ontologie bezeichnet.

Der Tableaux-Reasoner sucht nach solch einem Modell durch Vervollständigung. Dieses wird inkrementell als eine Art Tafel (eben, Tableau) aufgebaut. Die Vervollständigung beginnt mit einem initialen Graphen der Abox. Dabei repräsentieren die Knoten Individuen und Literale (z.B. Zeichenketten, Datumswerte oder auch Nummern). Jedem Knoten wird der entsprechende (Daten-) Typ zugewiesen. Die gerichteten Kanten zwischen den Knoten, stellen die Eigenschaften dar. 

Durch wiederholtes Anwenden der Regeln zur Erweiterung des Graphen, versucht der Reasoner einen widerspruchsfreien Graphen zu bilden. Dies tut er solange bis entweder ein Widerspruch (Kontradiktion) auftritt oder keine Regeln mehr anwendbar sind.

Nachfolgend ein Beispiel, gegeben sei:
$ Prolog \subseteq LogischeProgrammiersprache, LogischeProgrammiersprache \subseteq Programmiersprache $
Man stellt nun folgende Anfrage:
$ if Prolog \subseteq Programmiersprache $

Der Prozess der Folgerung findet nun wie folgt statt:
\begin{itemize}
    \item Testen, ob ein Individuum existiert, welches eine logische Programmiersprache, aber keine Programmiersprache ist.\\
        Man möchte also die Erfüllbarkeit des Konzeptes $ C_0 = (Prolog \sqcap \neg Programmiersprache) $ testen.\\
        Es wird also versucht die Erfüllbarkeit mittels Widerspruch zu beweisen.
    \item $ C_0(x) \Rightarrow Prolog(x), (\neg Programmiersprache)(x) $
    \item $ Prolog(x) \Rightarrow LogischeProgrammiersprache(x) $
    \item $ LogischeProgrammiersprache(x) \Rightarrow Programmiersprache(x) $
        $ \Rightarrow $ Konflikt!
\end{itemize}
Wie ersichtlich ist, ist das Konzept $ C_0 $ nicht erfüllbar, die Anfrage $ Prolog \subseteq Programmiersprache $ trifft somit innerhalb der gegebenen Ontologie zu.

Alle anderen Aufgaben zum Ziehen von Schlüssen können als Konsistenzprüfungen definiert werden.

Die Strategien zur Vervollständigung eines Modelles werden unter~\cite[Seiten 7 bis 9]{sirin:pellet05} ausführlich beschrieben.

% TODO ----------------------------



Der generelle Prozess der Folgerung läuft wie folgt ab:
\begin{itemize}
    \item Umwandlung eines Konzeptes bzw.\ der Konzepte in die negierte Normalform (NNF), die Negation $ \neg $ befindet sich vor Konzeptnamen.
    \item Ablegen des umgewandelten Konzeptes als $ C_0 $.

        Der Algorithmus hat also die Datenbasis (Abox) $ A_0 = {C_0(x_0)} $
    \item Regeln zur Transformation auf die Datenbasis (Abox) so weit als möglich anwenden.
    \item Wurde eine gültige Datenbasis (Abox) gefunden, so ist $ C_0 $ erfüllbar.
    \item Wurde keine gültige Datenbasis unter Berücksichtigung aller (Such-) Pfade gefunden, so ist $ C_0 $ nicht erfüllbar.
\end{itemize} (vgl.~\cite{horrocks2002} und~\cite{horrocks2005})

Gegeben seien folgende Datensätze, welche Regeln definieren

\begin{lstlisting}[caption={Aussagentripel bestehend aus Objekt, Prädikat und Subjekt},captionpos=b,label=lst:reasoning_seilpark]
    ``Schweiz hatRegion Solothurn.''
    ``Solothurn hatOrt Balmberg.''
    ``Seilpark istUnterklasseVon Ausflug.''
    ``Seilpark hatStandort Balmberg.''
\end{lstlisting}

definiert.

Unterstützt nun ein Programm Inferenz, z.B. durch einen Reasoner, so kann dieser schlussfolgern, dass der Ausflug \textit{Seilpark} in der Region Solothurn ist (vgl.~\cite[Abschnitt `Examples']{w3inference}).

% TODO END ----------------------------

\subsubsection{Datentypenprüfung}
\label{ssubsection:inferenz_pellet_datatypes}
In OWL werden Datentypen in einem XML-Schema beschrieben. Dadurch sind viele einfache Datentypen bereits gegeben, so z.B.\ numerische Datentypen (Ganz- und Fliesskommazahlen) und Zeichenketten. OWL bietet des Weiteren die Möglichkeit eigene Datentypen zu definieren.

Das Modul zur Datentypenprüfung prüft ob die Schnittmenge von Datentypen konsistent ist. Eine Schnittmenge von Datentypen ist dann inkonsistent, wenn diese keine Elemente gemeinsam haben.

Der Tableaux-Reasoner nutzt das Modul um für jeden Literal-Knoten des Graphen der Abox festzustellen, ob die Schnittmenge aller Datentypen eines jeden Knotens erfüllbar ist.

\subsubsection{Schnittstelle zur Wissensdatenbank (KB)}
\label{ssubsection:inferenz_pellet_kb}
Alle Aufgaben zum Ziehen von Schlüssen können auf eine Konsistenzprüfung anhand der Wissensdatenbank (KB) reduziert werden. Die Schnittstelle zur Wissensdatenbank entscheidet, wann die Konsistenz der Abox geprüften werden muss, wann alle Konzepte neu klassifizert werden müssen oder wann alle Individuen umgesetzt werden. %TODO WTF!?

Die Schnittstelle bietet die Möglichkeit beliebige atomare Anfragen zu beantworten. Diese können Klassen, Eigenschaften oder Individuen betreffen. Wahrheitsabfragen werden in Erfüllbarkeitsprobleme umgewandelt.

Für Anfragen, welche mehrere Ergebnisse zurückliefern, sind theoretisch mehrere Konsistenzprüfungen notwendig. Da dies aber sehr aufwändig ist, werden die im~\autoref{subsection:inferenz_pellet_opti} beschriebenen Verfahren zur Optimierung genutzt.

Die Schnittstelle, wie auch der Rest der internen Komponenten von Pellet, baut auf der ATerm-Bibliothek~\footnote{\url{https://strategoxt.org/Tools/ATermLibrary}} auf. ATerm (Annotated Term) ist ein abstratker Datentyp, welcher für den Austausch von baumartigen Datenstrukturen zwischen verteilten Applikationen konzipiert wurde.

\subsubsection{Abox Query-Engine}
\label{ssubsection:inferenz_pellet_aboxquery}
Die Schnittstelle zur Wissensdatebank ist mit einer Abox Query-Engine gekoppelt. Diese beantwortet konjunktive (verknüpfte) Anfragen. Das Modul unterstützt in SPARQL oder RQDL~\footnote{\url{http://www.w3.org/Submission/RDQL/}} geschriebene Anfragen. Diese müssen aber gewisse Einschränkungen erfüllen, Details siehe~\cite[Seiten 10 und 11]{sirin:pellet05}.

Die Abox Query-Engine besteht im Grunde aus mehreren Query-Engines, welche Anfragen beantworten. Dabei gibt es eine zentrale Query-Engine, welche Anfragen vorverabeitet und die angemessene Query-Engine auswählt um eine Anfrage zu beantworten. Details zum genauen Ablauf, siehe~\cite[Seite 11]{sirin:pellet05}.

\begin{figure}[htbp]
    \centering \rotatebox{0}{\scalebox{0.3}[0.3]{\includegraphics{bilder/infres_pellet_queryengine.png}}}
    \caption{Ablauf Beantwortung einer Anfrage in der Abox Query-Engine.\label{fig:pellet_queryengine_komponenten}\protect\footnotemark}
\end{figure}
\footnotetext{\cite[S. 11]{sirin:pellet05}}

\subsubsection{Gültigkeitsprüfung bezüglich OWL-DL}
\label{ssubsection:inferenz_pellet_owldl}
Werkzeuge zur Modellierung und Export von Ontologien im OWL-Format, bieten häufig Charakteristika von OWL-full zur Modellierung an. Bei der Gültigkeitsprüfung einer Ontologie wird diese analysiert und gegebenenfalls mittels Heuristiken von OWL-full in OWL-DL umgewandelt.

Diese Umwandlung ist jedoch nur in gewissen Fällen möglich, so z.B.\ gleiche Bezeichnung von Klassen, Eigenschaften und Individuen, andernfalls werden die OWL-full Charakteristika ignoriert oder der Prozess wird komplett abgebrochen.

\subsection{Behandlung von Regeln in Pellet}
\label{subsection:inferenz_pellet_swrl}
Pellet ermöglicht die Verwendung von in SWRL formulierten Regeln zum Ziehen von Schlüssen. Damit die in der Wissensdatenbank gespeicherten Konzepte in den Regeln verfügbar sind, wird das $\mathcal{AL}$-Log-Framework eingesetzt. Dieses verbindet Beschreibungslogik mit Regeln.~\cite[Seiten 4 und 5]{sirin:pellet07} $\mathcal{AL}$-Log ist ein integriertes System zur Repräsentation von Wissen, welches auf der Beschreibungslogik $\mathcal{AL}$ und der deduktiven Datenbanksprache Datalog basiert.~\cite{allog} Bei $\mathcal{AL}$ handelt es sich um eine minimale Sprache der Beschreibungslogik, Details siehe~\cite[Seite 51]{dl:baader2003}. Als Implementation des $\mathcal{AL}$-Log-Frameworks nutzt Pellet einen Datalog-Reasoner.~\cite[Seiten 4 und 5]{sirin:pellet07}

Bei Datalog handelt es sich um eine deklarative Logiksprache, in welcher jede Formel eine funktionsfreie Hornklausel ist. Im Unterschied zu Prolog muss jede Variable, die im Kopf einer Klausel vorkommt, auch im Körper der Klausel vorkommen. Weiter spielt die Reihenfolge, in welcher die Klauseln angegeben werden, keine Rolle. Alle Anfragen terminieren und jede mögliche Antwort wird ausgegeben.~\cite{datalog}

In der Pellet-Implementation wird das $\mathcal{AL}$-Log-Framework dahingehend erweitert, dass es die Beschreibungslogik $\mathcal{SHOIQ}(\mathcal{D})$ nutzen kann. Die Erweiterung erlaubt zudem die Verwendung von OWL-Datentypen und SWRL-Funktionen im Körper von Datalog-Regeln.~\cite[Seite 5]{sirin:pellet07}

\subsection{Optimierungen}
\label{subsection:inferenz_pellet_opti}
Dieser Abschnitt basiert, sofern nicht anders im Text vermerkt, auf~\cite[Seiten 16 bis 19]{sirin:pellet05}

Beschreibungslogiken, wie $\mathcal{SHOIQ}(\mathcal{D})$ haben im schlechtesten Fall eine sehr hohe Komplexität. Daher unterscheidet sich die effektive Implementation einer solchen sehr stark von deren Design bzw. Theorie.

Um dennoch akzeptable Leistungen beim Ziehen von Schlüssen mittels Beschreibungslogik zu erhalten, nutzen moderne Reasoner verschiedene Arten von Optimierungen, so z.B.:

\begin{itemize}
    \item \textbf{Normalisierung und Vereinfachung}\\
        Alle Konzepte der Wissensdatenbank werden in eine Form gebracht, so dass Widersprüche möglichst früh während der Tableaux-Erweiterung erkannt werden können. Sie werden also in die Normalform gebracht.\\
        Die Vereinfachung erkennt offensichtliche Fehler während der Normalisierung. Weiter werden mehrfache Vorkommen eines Konzeptes eliminiert.

    \item \textbf{Tbox-Absorption}\\
        Bei dem Prozess der Tbox-Absorption wird versucht gleiche Konzepte (GCI --- General Concept Inclusion) zu eliminieren, indem diese mit Definitionen atomarer Konzepte ersetzt werden.

    \item \textbf{Dependency-directed Backjumping}\\
        Der Prozess des dependency-directed Backjumpings eliminiert unproduktive Backtracking-Suchen, indem er herausfindet welche Verzweigungspunkte Konflikte verursachen. Er springt dann zurück und überspringt dabei diese Punkte ohne nach Alternativen zu suchen.
\end{itemize}

Weitere Verfahren zur Optimierung sowie mehr Details finden sich unter~\cite[S. 17 bis 19]{sirin:pellet05}.


\subsection{Unterschiede zu Prolog}
\label{}
Datalog: in kopf verwendete variablen müssen auch im körper vorkommen. in prolog nicht. anfragen terminieren in datalog, jede mögliche antwort wird zurückgegeben, in prolog ist dies nicht gegeben, endlosschleifen möglich, die reihenfolge von regeln spielt eine rolle.~\cite[Seite 175]{laemmel}

Ein weiterer, fundamentaler Unterschied ist die Art, wie Schlüsse gezogen werden. Prolog basiert grundsätzlich auf dem SLD-Resolutionsverfahren~\citep[Details siehe][Seite 68]{laemmel}. Im Gegensatz dazu kommt bei dem eingesetzten Reasoner der Tableau-Algorithmus zum Einsatz.

So ist es in Prolog ohne Weiteres möglich so genannte Constraint-Satisfaction-Probleme (Bedingungserfüllungsprobleme) zu lösen~\citep[Details siehe][Seite 148]{laemmel}. Mit Pellet bzw. Ontologien und Regeln ist dies nicht ohne Weiteres möglich. Versuche dazu finden sich unter~\citet{xiong2008constraint},~\citet{staab2006constraint} und~\citet{bramer2007constraint}.

\noindent\rule[1ex]{\textwidth}{1pt}
\begin{wrapfigure}[14]{l}{0.1\textwidth}
    \vspace{-12pt}
    \includegraphics[width=0.1\textwidth]{bilder/elephant.png}
\end{wrapfigure}
Das unter~\ref{lst:reasoning_seilpark} genannte Beispiel beantwortet genau die unter~\ref{sec:wissensrepFormen_Wissensnetze} gestellte Frage, wie man zum Schluss gelangt, dass das Individuum \textit{Seilpark Balmberg} in der \textit{Region} \textit{Solothurn} ist.

Wie wendet man dies jedoch an? Wie gelangt man effektiv zu dieser Information? Kann dies effektiv durch reine Folgerung erreicht werden?

Die Antwort hierzu lautet ja und nein. Modelliert man die Situation beispielsweise in Protégé und nutzt den Pellet-Reasoner zum Ziehen von Schlüssen, so würde man annehmen, dass dies der Fall ist. Rein von den Möglichkeiten her sollte der Reasoner genau dies bieten. Dies ist jedoch nicht ganz der Fall, wie in der nachfolgenden Grafik ersichtlich ist.

\begin{figure}[H]
\centering \rotatebox{0}{\scalebox{0.5}[0.5]{\includegraphics{bilder/inferenz_protege.png}}}
\caption{Darstellung des Individuums \textit{Seilpark Balmberg} in Protégé.\label{fig:inferenz_protege}\protect\footnotemark}
\end{figure}
\footnotetext{Eigene Darstellung mittels Stanford Protégé Version 5.0.0 beta 15}

Eine solche Folgerung ist durchaus möglich, man muss den Relationen die entsprechenden Eigenschaften, wie Symmetrie oder Transitivität, geben. Wir haben dies in unserem Fall jedoch bewusst nicht getan, da sonst Folgerungen auftreten, welche irreführend sind, so wäre dann z.B.\ ein Ort auch ein Land und umgekehrt.

Wir haben die eigentliche Folgerung mittels einer Regel in der Ontologie vorgenommen. Dies führen wir zu einem späteren Zeitpunkt noch genauer aus.

\noindent\rule[1ex]{\textwidth}{1pt}
